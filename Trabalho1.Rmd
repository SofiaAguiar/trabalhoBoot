---
title: "<span style='font-size: 32px'>Intervalo de confiança bootstrap básico <br>para a variância populacional</span>"
author: |
  | <span style='font-size: 16px'>Aline Cristina (2020031412)</span>
  | <span style='font-size: 16px'>Herikeli Mendes (2020031560)</span>   
  | <span style='font-size: 16px'>Marcel Zanetti (2020031706)</span> 
  | <span style='font-size: 16px'>Renan Machado (2020031773)</span> 
  | <span style='font-size: 16px'>Sofia Aguiar (2020031811)</span> 
output: 
    html_document:
        highlight: textmate
        theme: flatly
        toc: yes
        toc_float:
            collapsed: yes
            smooth_scroll: yes 

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

if (!require(pacman)) install.packages('pacman')
library(pacman)
pacman::p_load(tidyverse, data.table, EnvStats, progress, gt)

load('simulacoes.RData')

```

```{r, echo=FALSE}
htmltools::img(src = 'https://d1yjjnpx0p53s8.cloudfront.net/styles/logo-thumbnail/s3/102013/ufmg_simbolo_vetorizado.jpg', 
               alt = 'UFMG', 
               style = 'position:absolute; top:0; right:0; padding: 25px; margin-right:10px;')
```

---

## Introdução

Nesse trabalho será realizado uma comparação de desempenho entre uma função bootstrap e a função VarTest (R) 

Segundo Horiwitz (2001) O bootstrap é uma técnica prática que está pronta para uso em aplicações. Esse método estima a distribuição de um estimador ou estatística de teste, resamplando os dados ou um modelo estimado a partir dos dados. Para realizar a comparação do trabalho a seguir foi executada uma função bootstrap com 200 reamostragens, utilizando o método para fazer probabilidades de cobertura de intervalos de confiança básicas para variância populacional. Entretanto a função bootstrap tem diversas outras aplicações como:  econométricas, aproximações às distribuições de estatísticas, e probabilidades de rejeição de testes de hipóteses, entre outras. 
A função VarTest é uma função paramétrica nativa do R, e ambas foram comparadas para comparação de desempenho.

Para ajudar nessa comparação fez-se necessário  a criação de um mecanismo da programação através da função MonteCarlo. Essa foi realizada em três principais etapas, sendo elas:
<br/>
Etapa 1 : Geração de uma amostra  bootstrap de tamanho 200, {Xi : i = 1, ..., 200}, amostrando a distribuição correspondente a Fn aleatoriamente.
<br/>
Etapa 2: Calculando T200 º T200 (X1 , … , X200).
<br/>
Etapa 3: os resultados de muitas repetições das etapas 1 e 2 foram usados para calcular o empírico probabilidade do evento T200 £ t (ou seja, a proporção de repetições em que esse evento ocorre).

Ele foi aplicado em três cenários de distribuições diferentes:

- Cenário 1: Distribuição normal

- Cenário 2: Distribuição Binomial 

- Cenário 3: Distribuição Exponencial 

Segundo Booth e Sarkar (1998) o número de reamostragens deve, de fato, ser determinado pelo coeficiente de variação condicional, envolvendo apenas a variabilidade da reamostragem. A análise condicional é baseada na crença de que o erro de Monte Carlo não deve determinar as conclusões de uma análise estatística. Diante disso em cada cenário da simulação foi considerado dez tamanhos amostrais(10, 50, 100, 250, 500, 1000, 2000, 3000, 4000 e 5000), para assim obter-se uma comparação entre os cenários, comparar seus desempenho de todos para diferentes tamanhos de amostra e assim avaliar qual é melhor para cada cenário e tamanho de amostra. 

## Estudo de simulação

### Distribuição normal

A distribuição normal tem função de densidade:
$$f(x)=\frac{1}{\sigma\sqrt{2\pi}}\cdot \exp\bigg(-\frac 12 \cdot \frac{(x-\mu )^2}{\sigma^2}\bigg)$$
Para todo _x_ real, em que $\sigma$ e $\mu$ são, respectivamente, a média e o desvio-padrão. Nas simulações deste trabalho, foi utilizada a normal padrão, i.e., a normal com média 0 e desvio-padrão 1. Um exemplo de gráfico de densidade de probabilidade da distribuição normal:

```{r echo=FALSE} 
tibble(x = -4:4) %>% 
  ggplot(aes(x)) +
  stat_function(fun = dnorm) +
  labs(title = "Densidade de probabilidade da distribuição normal",
       x = "x", y = "f(x)")

```

A estimação de variância pela função _varTest_ do pacote _EnvStats_, usada para comparação com o método de Bootstrap, é feita usando um teste de qui-quadrado, que é bastante sensível a desvios de normalidade (em particular se os dados são bastante assimétricos). Como, em geral, métodos paramétricos são mais poderosos que métodos não-paramétricos quando os pressupostos dos primeiros são satisfeitos, é esperado que, aqui, das distribuições testadas, o Bootstrap obtenha a maior desvantagem em relação à função _varTest_. 

Iniciamente, foi feito um gráfico para comparar o desempenho dos métodos com variados tamanhos de amostra: 10, 50, 100, 250, 500, 1000, 2000, 3000, 4000 e 5000.

```{r gráfico 2, echo=FALSE}
normal_por_n_df %>%
  pivot_longer(cols = c("bootstrap", "param"), names_to = "tipo", values_to = "valor") %>% 
  mutate(tipo = ifelse(tipo == "bootstrap", "Bootstrap", "Paramétrico")) %>% 
  ggplot(aes(x, valor, color = tipo)) +
  geom_path() +
  geom_point() +
  labs(x = "Tamanho da amostra", y = "Precisão",
       title = "Precisão da variância em amostras de diferentes tamanhos",
       subtitle = "Simulações de Monte Carlo comparando Bootstrap e métodos paramétricos",
       colour = "Método") +
  scale_x_continuous(breaks = c(100, 500, 1000, 2000, 3000, 4000, 5000))
```

Depois, foram feitas 10 diferentes execuções de Monte Carlo usando uma amostra pequena, de tamanho 100, para testar a estabilidade dos valores apresentados em um cenário levemente desfavorável.

```{r gráfico 3, echo=FALSE}

normal_100_nvezes_df %>% 
  pivot_longer(cols = starts_with("resultados"), names_to = "Metodo", values_to = "Resultado") %>% 
  ggplot(aes(x = Metodo, y = Resultado)) +
  geom_point()

```

### Distribuição binomial

A distribuição binomial é uma distribuição discreta de probabilidade, estando associada a um experimento de múltiplas etapas. A mesma possui como função de densidade:

$$p_{X}(x)= \binom{n}{x}p^{x}(1-p)^{n-x}$$

onde,
$$\binom{n}{x}= \frac{n!}{x!(n-x)!}$$
A seguir, é possível observar um exemplo de gráfico de densidade de probabilidade da distribuição binomial:

```{r gráfico 4, echo=FALSE} 
tibble(x = 0:12, y = dbinom(0:12, 12, 0.5)) %>% 
  ggplot(aes(x = x, y=y)) +
  geom_line() +
  labs(title = "Densidade de probabilidade da distribuição binomial",
       x = "x", y = "f(x)")

```

Assim como para a distribuição anterior, o gráfico a seguir foi construído para comparar o desempenho dos métodos com diferentes tamanhos de amostra (10, 50, 100, 250, 500, 1000, 2000, 3000, 4000 e 5000) e possuindo p como 0.5:

```{r gráfico 5, echo=FALSE}
binomial_por_n_df %>%
  pivot_longer(cols = c("bootstrap", "param"), names_to = "tipo", values_to = "valor") %>% 
  mutate(tipo = ifelse(tipo == "bootstrap", "Bootstrap", "Paramétrico")) %>% 
  ggplot(aes(x, valor, color = tipo)) +
  geom_path() +
  geom_point() +
  labs(x = "Tamanho da amostra", y = "Precisão",
       title = "Precisão da variância em amostras de diferentes tamanhos",
       subtitle = "Simulações de Monte Carlo comparando Bootstrap e métodos paramétricos",
       colour = "Método") +
  scale_x_continuous(breaks = c(100, 500, 1000, 2000, 3000, 4000, 5000))
```

A partir do mesmo é possível observar como o método bootstrap é mais sensível a amostras de tamanhos pequenos. 

Em seguida, foram feitas 10 diferentes execuções de Monte Carlo para uma amostra de tamanho 100, para observar o comportamento para um cenário levemente desfavorável (pequeno):

```{r gráfico 6, echo=FALSE}
binomial_100_nvezes_df %>% 
  pivot_longer(cols = starts_with("resultados"), names_to = "Metodo", values_to = "Resultado") %>% 
  ggplot(aes(x = Metodo, y = Resultado)) +
  geom_point()
```

Como pode ser contemplado, pouco se diferiu os resultados obtidos pelos intervalos de confiança para as distribuições normal e binomial.


### Distribuição exponencial

A função exponencial tem função densidade:
$$f(x)=\lambda \cdot e^{-\lambda\cdot x}\ \ \ \forall x\geq 0$$ 
Tendo isto em mente, temos o grafico da função exponencial que tem como parâmetros $$E(X)=\frac{1}{\lambda}$$ e variância $$V(X)=\frac{1}{\lambda^2}$$

```{r gráfico 7, echo=FALSE}
tibble(x = 0:8) %>% 
  ggplot(aes(x)) +
  stat_function(fun = dexp) +
  labs(title = "Densidade de probabilidade da distribuição exponencial",
       x = "x", y = "f(x)")

```
<br/>
<br/>
```{r gráfico 8, echo=FALSE}
exponencial_por_n_df %>%
  pivot_longer(cols = c("bootstrap", "param"), names_to = "tipo", values_to = "valor") %>% 
  mutate(tipo = ifelse(tipo == "bootstrap", "Bootstrap", "Paramétrico")) %>% 
  ggplot(aes(x, valor, color = tipo)) +
  geom_path() +
  geom_point() +
  labs(x = "Tamanho da amostra", y = "Precisão",
       title = "Precisão da variância em amostras de diferentes tamanhos\ndistribuição exponencial",
       subtitle = "Simulações de Monte Carlo comparando Bootstrap e métodos paramétricos no método\ndistribuição exponencial",
       colour = "Método") +
  scale_x_continuous(breaks = c(100, 500, 1000, 2000, 3000, 4000, 5000))
```
<br/>
<br/>
```{r gráfico 9, echo=FALSE}

exponencial_100_nvezes_df %>% 
  pivot_longer(cols = starts_with("resultados"), names_to = "Exponencial", values_to = "Resultado") %>%
  ggplot(aes(x = Exponencial, y = Resultado)) +
  geom_point()
```

Em comparação com as distribuições anteriroes temos duas diferenças principais. A primeira delas é a eficiência relativa do Bootstrap em relação aos métodos paramétricos, proporcionalmente, a eficiência não passa de 85%, enquanto nas outras distribuições a eficiência é maior que 90%. A grande surpresa observada é o comportamento oposto às distribuições binomial e normal, no método paramétrico, não chegando a 66% de eficiência. Quanto à precisão, percebe-se que o Bootstrap apresenta resultados tão bons quanto os resultado das outras distribuições.

## Comparação geral

Por fim, para o tamanho 1000, são sintetizados, em uma tabela, os resultados dos métodos paramétrico e não-paramétrico das três distribuições abordadas: normal (padrão), exponencial (com taxa 2) e binomial (com n = 1000 e p = 0.5).

```{r tabela 1, echo=FALSE}

resultados_gerais %>%
  mutate(Método = c("Bootstrap", "Paramétrico")) %>% 
  select(c(4,1,2,3)) %>% gt() %>% 
  tab_header(title = md("**Comparação de método Bootstrap e paramétrico para diferentes distribuições**"))

```

## Apêndice

#### Código feito para construir as funções Bootstrap e Monte Carlo

```{r, eval=FALSE}
# Bibliotecas necessárias
if (!require(pacman)) install.packages('pacman')
library(pacman)
pacman::p_load(tidyverse, data.table, EnvStats, progress, gt)

# 1. Função bootstrap para IC básico para variancia populacional, dada uma amostra A----
# 200 reamostragens e ic de 95% de confiança

bootstrap_varbasica = function(A){
  
  thetaPontual = var(A)
  b = 1
  B = 200
  reamostragem = list()
  reamostragem[[1]] = c(1:B)
  reamostragem[[2]] = numeric(B)
  
  while (b <= B) {
    b_i = sample(A, length(A), replace = T)
    thetaBoot = var(b_i)
    reamostragem[[2]][[b]] = thetaBoot
    b = b + 1
  }
  
  alfa = 0.05
  thetaInf = quantile(reamostragem[[2]], alfa/2)
  thetaSup = quantile(reamostragem[[2]], 1-alfa/2)
  valorInf = 2*thetaPontual - thetaSup
  valorSup = 2*thetaPontual - thetaInf
  return(c(valorInf, valorSup))

}

# 2. Função Monte Carlo para comparar o desempenho da função bootstrap e o método paramétrico----

montecarlo <- function(n, FUN, theo_val, ...) {
  
  int_confianca <- data.table(valor = rep(theo_val, 1000),
                              InfBoot = numeric(1000),
                              SupBoot = numeric(1000),
                              InfParam = numeric(1000),
                              SupParam = numeric(1000))
  pb <- progress_bar$new(total=1000)
  
  for (iter in 1:1000) {
    amostra_iter <- FUN(n, ...)
    
    int_confianca[iter, 2:5] <- data.table(
      reduce(list(bootstrap_varbasica(amostra_iter),
                  varTest(amostra_iter)$conf.int[c(1,2)]), c)) %>% transpose()
     pb$tick()
  }

  return(list(.001 * nrow(int_confianca[valor %between% list(InfBoot, SupBoot)]), # Bootstrap
              .001 * nrow(int_confianca[valor %between% list(InfParam, SupParam)]))) # Paramétrico

}

# 3. Gráficos e tabelas ----

# 3.1 Gráfico 2 ----
normal_por_n_df <- tibble(x = c(10, 50, 100, 250, 500, 1000, 2000, 3000, 4000, 5000))

pb <- progress_bar$new(total = length(normal_por_n_df$x))
normal_por_n <- map(normal_por_n_df$x, ~{pb$tick(); montecarlo(.x, rnorm, 1)})

normal_por_n_df <- normal_por_n_df %>% 
  mutate(bootstrap = map_dbl(1:nrow(normal_por_n_df), ~pluck(normal_por_n, .x, 1)),
         param = map_dbl(1:nrow(normal_por_n_df), ~pluck(normal_por_n, .x, 2)))

# 3.2 Gráfico 3 ----
normal_100_nvezes <- map(1:10, ~montecarlo(100, rnorm, 1))

normal_100_nvezes_df <- tibble(
  resultados_boots = map_dbl(1:10, ~pluck(normal_100_nvezes, .x, 1)),
  resultados_param = map_dbl(1:10, ~pluck(normal_100_nvezes, .x, 2))
)

# 3.4 Gráfico 5 ----
var_binom=function(n,p){
  return(n * p * (1 - p))
}

binomial_por_n_df <- tibble(x = c(10, 50, 100, 250, 500, 1000, 2000, 3000, 4000, 5000))

pb <- progress_bar$new(total = length(binomial_por_n_df$x))
binomial_por_n <- map(binomial_por_n_df$x, ~{pb$tick(); montecarlo(.x,
                                                                   rbinom,
                                                                   theo_val=var_binom(.x, 0.5),
                                                                   prob=0.5,
                                                                   size=.x)})
binomial_por_n_df <- binomial_por_n_df %>% 
  mutate(bootstrap = map_dbl(1:nrow(binomial_por_n_df), ~pluck(binomial_por_n, .x, 1)),
         param = map_dbl(1:nrow(binomial_por_n_df), ~pluck(binomial_por_n, .x, 2)))

# 3.5 Gráfico 6 ----
binomial_100_nvezes <- map(1:10, ~montecarlo(100,
                                             rbinom,
                                             theo_val=var_binom(100, 0.5),
                                             prob=0.5,
                                             size=100))

binomial_100_nvezes_df <- tibble(
  resultados_boots = map_dbl(1:10, ~pluck(binomial_100_nvezes, .x, 1)),
  resultados_param = map_dbl(1:10, ~pluck(binomial_100_nvezes, .x, 2))
)

# 3.6 Gráfico 8 ----
exponencial_por_n_df <- tibble(x = c(10, 50, 100, 250, 500, 1000, 2000, 3000, 4000, 5000))

pb <- progress_bar$new(total = length(exponencial_por_n_df$x))
exponencial_por_n <- map(exponencial_por_n_df$x, ~{pb$tick(); montecarlo(.x,
                                                                         rexp,
                                                                         rate=2,
                                                                         theo_val= .25)})

exponencial_por_n_df <- exponencial_por_n_df %>% 
  mutate(bootstrap = map_dbl(1:nrow(exponencial_por_n_df), ~pluck(exponencial_por_n, .x, 1)),
         param = map_dbl(1:nrow(exponencial_por_n_df), ~pluck(exponencial_por_n, .x, 2)))

# 3.7 Gráfico 9 ----
exponencial_100_nvezes <- map(1:10, ~montecarlo(100, rexp, rate=2, theo_val= .25))

exponencial_100_nvezes_df <- tibble(
  resultados_boots = map_dbl(1:10, ~pluck(exponencial_100_nvezes, .x, 1)),
  resultados_param = map_dbl(1:10, ~pluck(exponencial_100_nvezes, .x, 2))
)


# 3.8 Tabela 1 ----
resultados_gerais <- tibble(
  normal = unlist(montecarlo(1000, rnorm, 1)),
  exponencial = unlist(montecarlo(1000, rexp, .25, rate = 2)),
  binomial = unlist(montecarlo(1000, rbinom, 250, size = 1000, prob = .5))
)

```

## Referências bibliográficas
BOOTH, James G.; SARKAR, Somnath. Monte Carlo approximation of bootstrap variances. The American Statistician, v. 52, n. 4, p. 354-357, 1998.
<br/>
<br/>
HOROWITZ, Joel L. The bootstrap. In: Handbook of econometrics. Elsevier, 2001. p. 3159-3228.
