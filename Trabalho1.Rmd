---
title: "<span style='font-size: 32px'>Intervalo de confiança bootstrap básico <br>para a variância populacional</span>"
author: |
  | <span style='font-size: 16px'>Aline Cristina (2020031412)</span>
  | <span style='font-size: 16px'>Herikeli Mendes (2020031560)</span>   
  | <span style='font-size: 16px'>Marcel Zanetti (2020031706)</span> 
  | <span style='font-size: 16px'>Renan Machado (2020031773)</span> 
  | <span style='font-size: 16px'>Sofia Aguiar (2020031811)</span> 
output: 
    html_document:
        highlight: textmate
        theme: flatly
        toc: yes
        toc_float:
            collapsed: yes
            smooth_scroll: yes 

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

if (!require(pacman)) install.packages('pacman')
library(pacman)
pacman::p_load(tidyverse, data.table, EnvStats, progress, gt)

load('simulacoes.RData')

```

```{r, echo=FALSE}
htmltools::img(src = 'https://d1yjjnpx0p53s8.cloudfront.net/styles/logo-thumbnail/s3/102013/ufmg_simbolo_vetorizado.jpg', 
               alt = 'UFMG', 
               style = 'position:absolute; top:0; right:0; padding: 25px; margin-right:10px;')
```

---

## Introdução

Nesse trabalho será realizado uma comparação de desempenho entre uma função bootstrap e a função VarTest (R) 

Segundo Horiwitz (2001) O bootstrap é uma técnica prática que está pronta para uso em aplicações. Esse método estima a distribuição de um estimador ou estatística de teste, resamplando os dados ou um modelo estimado a partir dos dados. Para realizar a comparação do trabalho a seguir foi executada uma função bootstrap com 200 reamostragens, utilizando o método para fazer probabilidades de cobertura de intervalos de confiança básicas para variância populacional. Entretanto a função bootstrap tem diversas outras aplicações como:  econométricas, aproximações às distribuições de estatísticas, e probabilidades de rejeição de testes de hipóteses, entre outras. 
A função VarTest é uma função paramétrica nativa do R, e ambas foram comparadas para comparação de desempenho.

Para ajudar nessa comparação fez-se necessário  a criação de um mecanismo da programação através da função MonteCarlo. Essa foi realizada em três principais etapas, sendo elas:
Etapa 1 : Geração de uma amostra  bootstrap de tamanho 200, {Xi *: i = 1, ..., 200}, amostrando a distribuição correspondente a Fn aleatoriamente.
Etapa 2: Calculando T200* º T200 (X1* ,…, X200*).
Etapa 3: os resultados de muitas repetições das etapas 1 e 2 foram usados para calcular o empírico probabilidade do evento T200 * £ t (ou seja, a proporção de repetições em que esse evento ocorre).

Ele foi aplicado em Tres cenários de distribuição diferentes diferentes:
- Cenário 1: Distribuição normal:

- Cenário 2: Distribuição Binomial 

- Cenário 3:Distribuição Exponencial 

E em cada cenário da simulação foi considerado três tamanhos amostrais(50,500,5000), para assim obter-se uma comparação entre os cenários, comparar a desempenho de todos para diferentes tamanhos de amostra e assim avaliar qual é melhor para cada cenário e tamanho de amostra.

## Estudo de simulação

### Distribuição normal

A distribuição normal tem função de densidade:
$$f(x)=\frac{1}{\sigma\sqrt{2\pi}}\cdot \exp\bigg(-\frac 12 \cdot \frac{(x-\mu )^2}{\sigma^2}\bigg)$$
Para todo _x_ real, em que $\sigma$ e $\mu$ são, respectivamente, a média e o desvio-padrão. Nas simulações deste trabalho, foi utilizada a normal padrão, i.e., a normal com média 0 e desvio-padrão 1. Um exemplo de gráfico de densidade de probabilidade da distribuição normal:

```{r}
tibble(x = -4:4) %>% 
  ggplot(aes(x)) +
  stat_function(fun = dnorm) +
  labs(title = "Densidade de probabilidade da distribuição normal",
       x = "x", y = "f(x)")

```

A estimação de variância pela função _varTest_ do pacote _EnvStats_, usada para comparação com o método de Bootstrap, é feita usando um teste de qui-quadrado, que é bastante sensível a desvios de normalidade (em particular se os dados são bastante assimétricos). Como, em geral, métodos paramétricos são mais poderosos que métodos não-paramétricos quando os pressupostos dos primeiros são satisfeitos, é esperado que, aqui, das distribuições testadas, o Bootstrap obtenha a maior desvantagem em relação à função _varTest_. 

Iniciamente, foi feito um gráfico para comparar o desempenho dos métodos com variados tamanhos de amostra: 10, 50, 100, 250, 500, 1000, 2000, 3000, 4000 e 5000.

```{r gráfico 2}
normal_por_n_df %>%
  pivot_longer(cols = c("bootstrap", "param"), names_to = "tipo", values_to = "valor") %>% 
  mutate(tipo = ifelse(tipo == "bootstrap", "Bootstrap", "Paramétrico")) %>% 
  ggplot(aes(x, valor, color = tipo)) +
  geom_path() +
  geom_point() +
  labs(x = "Tamanho da amostra", y = "Precisão",
       title = "Precisão da variância em amostras de diferentes tamanhos",
       subtitle = "Simulações de Monte Carlo comparando Bootstrap e métodos paramétricos",
       colour = "Método") +
  scale_x_continuous(breaks = c(100, 500, 1000, 2000, 3000, 4000, 5000))
```

Depois, foram feitas 10 diferentes execuções de Monte Carlo usando uma amostra pequena, de tamanho 100, para testar a estabilidade dos valores apresentados em um cenário levemente desfavorável.

```{r gráfico 3}

normal_100_nvezes_df %>% 
  pivot_longer(cols = starts_with("resultados"), names_to = "Metodo", values_to = "Resultado") %>% 
  ggplot(aes(x = Metodo, y = Resultado)) +
  geom_point()

```

### Distribuição exponencial

A função exponencial tem função densidade:
$$f(x)=\lambda \cdot e^{-\lambda\cdot x}\ \ \ \forall x\geq 0$$ 
Tendo isto em mente, temos o grafico da função exponencial que tem como parâmetros $$E(X)=\frac{1}{\lambda}$$ e variância $$V(X)=\frac{1}{\lambda^2}$$
```{r}
tibble(x = 0:8) %>% 
  ggplot(aes(x)) +
  stat_function(fun = dexp) +
  labs(title = "Densidade de probabilidade da distribuição exponencial",
       x = "x", y = "f(x)")

```

```{r gráfico 22}
exponencial_por_n_df %>%
  pivot_longer(cols = c("bootstrap", "param"), names_to = "tipo", values_to = "valor") %>% 
  mutate(tipo = ifelse(tipo == "bootstrap", "Bootstrap", "Paramétrico")) %>% 
  ggplot(aes(x, valor, color = tipo)) +
  geom_path() +
  geom_point() +
  labs(x = "Tamanho da amostra", y = "Precisão",
       title = "Precisão da variância em amostras de diferentes tamanhos\ndistribuição exponencial",
       subtitle = "Simulações de Monte Carlo comparando Bootstrap e métodos paramétricos no método\ndistribuição exponencial",
       colour = "Método") +
  scale_x_continuous(breaks = c(100, 500, 1000, 2000, 3000, 4000, 5000))
```
```{r gráfico 33}

exponencial_100_nvezes_df %>% 
  pivot_longer(cols = starts_with("resultados"), names_to = "Exponencial", values_to = "Resultado") %>% 
  ggplot(aes(x = Metodo, y = Resultado)) +
  geom_point()

```




## Comparação geral

Por fim, para o tamanho 1000, são sintetizados, em uma tabela, os resultados dos métodos paramétrico e não-paramétrico das três distribuições abordadas: normal (padrão), exponencial (com taxa 2) e binomial (com n = 1000 e p = 0.5).

```{r tabela 1}

resultados_gerais %>%
  mutate(Método = c("Bootstrap", "Paramétrico")) %>% 
  select(c(4,1,2,3)) %>% gt() %>% 
  tab_header(title = md("**Comparação de método Bootstrap e paramétrico para diferentes distribuições**"))

```

## Apêndice

#### Código feito para construir as funções Bootstrap e Monte Carlo

```{r, eval=FALSE}
# Bibliotecas necessárias
if (!require(pacman)) install.packages('pacman')
library(pacman)
pacman::p_load(tidyverse, data.table, EnvStats, progress, gt)

# 1. Função bootstrap para IC básico para variancia populacional, dada uma amostra A----
# 200 reamostragens e ic de 95% de confiança

bootstrap_varbasica = function(A){
  
  thetaPontual = var(A)
  b = 1
  B = 200
  reamostragem = list()
  reamostragem[[1]] = c(1:B)
  reamostragem[[2]] = numeric(B)
  
  while (b <= B) {
    b_i = sample(A, length(A), replace = T)
    thetaBoot = var(b_i)
    reamostragem[[2]][[b]] = thetaBoot
    b = b + 1
  }
  
  alfa = 0.05
  thetaInf = quantile(reamostragem[[2]], alfa/2)
  thetaSup = quantile(reamostragem[[2]], 1-alfa/2)
  valorInf = 2*thetaPontual - thetaSup
  valorSup = 2*thetaPontual - thetaInf
  return(c(valorInf, valorSup))

}

# 2. Função Monte Carlo para comparar o desempenho da função bootstrap e o método paramétrico----

montecarlo <- function(n, FUN, theo_val, ...) {
  
  int_confianca <- data.table(valor = rep(theo_val, 1000),
                              InfBoot = numeric(1000),
                              SupBoot = numeric(1000),
                              InfParam = numeric(1000),
                              SupParam = numeric(1000))
  pb <- progress_bar$new(total=1000)
  
  for (iter in 1:1000) {
    amostra_iter <- FUN(n, ...)
    
    int_confianca[iter, 2:5] <- data.table(
      reduce(list(bootstrap_varbasica(amostra_iter),
                  varTest(amostra_iter)$conf.int[c(1,2)]), c)) %>% transpose()
     pb$tick()
  }

  return(list(.001 * nrow(int_confianca[valor %between% list(InfBoot, SupBoot)]), # Bootstrap
              .001 * nrow(int_confianca[valor %between% list(InfParam, SupParam)]))) # Paramétrico

}

# 3. Gráficos e tabelas ----

# 3.1 Gráfico 2 ----
normal_por_n_df <- tibble(x = c(10, 50, 100, 250, 500, 1000, 2000, 3000, 4000, 5000))

pb <- progress_bar$new(total = length(normal_por_n_df$x))
normal_por_n <- map(normal_por_n_df$x, ~{pb$tick(); montecarlo(.x, rnorm, 1)})

normal_por_n_df <- normal_por_n_df %>% 
  mutate(bootstrap = map_dbl(1:nrow(normal_por_n_df), ~pluck(normal_por_n, .x, 1)),
         param = map_dbl(1:nrow(normal_por_n_df), ~pluck(normal_por_n, .x, 2)))

# 3.2 Gráfico 3 ----
normal_100_nvezes <- map(1:10, ~montecarlo(100, rnorm, 1))

normal_100_nvezes_df <- tibble(
  resultados_boots = map_dbl(1:10, ~pluck(normal_100_nvezes, .x, 1)),
  resultados_param = map_dbl(1:10, ~pluck(normal_100_nvezes, .x, 2))
)

# 3.3 Tabela 1 ----
resultados_gerais <- tibble(
  normal = unlist(montecarlo(1000, rnorm, 1)),
  exponencial = unlist(montecarlo(1000, rexp, .25, rate = 2)),
  binomial = unlist(montecarlo(1000, rbinom, 250, size = 1000, prob = .5))
)

```